#!/usr/bin/env python3
"""
ğŸ“Š åˆ†æä¸‰ç§Curveæ•°æ®æ ¼å¼çš„å·®å¼‚
åˆ†æåŒä¸€æ± å­çš„batch_historicalã€comprehensive_free_historicalã€self_built_historicalæ–‡ä»¶å·®å¼‚
"""

import pandas as pd
import numpy as np
from pathlib import Path

def analyze_3pool_data_formats():
    """åˆ†æ3poolçš„ä¸‰ç§æ•°æ®æ ¼å¼å·®å¼‚"""
    
    print("ğŸ“Š Curve Financeæ•°æ®æ ¼å¼å·®å¼‚åˆ†æ")
    print("=" * 80)
    
    cache_dir = Path("free_historical_cache")
    
    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    files = {
        'batch_historical': cache_dir / "3pool_batch_historical_365d.csv",
        'comprehensive_free_historical': cache_dir / "3pool_comprehensive_free_historical_365d.csv", 
        'self_built_historical': cache_dir / "3pool_self_built_historical_365d.csv"
    }
    
    data = {}
    
    # è¯»å–æ‰€æœ‰æ–‡ä»¶
    for name, filepath in files.items():
        if filepath.exists():
            try:
                df = pd.read_csv(filepath)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                data[name] = df
                print(f"âœ… {name}: {len(df)} æ¡è®°å½•")
            except Exception as e:
                print(f"âŒ {name}: è¯»å–å¤±è´¥ - {e}")
        else:
            print(f"âš ï¸ {name}: æ–‡ä»¶ä¸å­˜åœ¨")
    
    if len(data) < 2:
        print("âŒ éœ€è¦è‡³å°‘2ä¸ªæ–‡ä»¶è¿›è¡Œæ¯”è¾ƒ")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ” è¯¦ç»†å·®å¼‚åˆ†æ")
    print("=" * 80)
    
    # 1. æ•°æ®ç»“æ„å·®å¼‚
    print("\nğŸ“‹ 1. æ•°æ®ç»“æ„ï¼ˆåˆ—ï¼‰å·®å¼‚:")
    print("-" * 60)
    
    for name, df in data.items():
        print(f"{name:30}: {len(df.columns)} åˆ—")
        print(f"{'':30}  {list(df.columns)}")
        print()
    
    # æ‰¾å‡ºå…±åŒåˆ—å’Œç‹¬æœ‰åˆ—
    all_columns = set()
    for df in data.values():
        all_columns.update(df.columns)
    
    print("ğŸ“Š åˆ—å·®å¼‚åˆ†æ:")
    common_cols = set(data[list(data.keys())[0]].columns)
    for df in list(data.values())[1:]:
        common_cols = common_cols.intersection(set(df.columns))
    
    print(f"   å…±åŒåˆ— ({len(common_cols)}): {sorted(common_cols)}")
    
    for name, df in data.items():
        unique_cols = set(df.columns) - common_cols
        if unique_cols:
            print(f"   {name} ç‹¬æœ‰åˆ—: {sorted(unique_cols)}")
    
    # 2. æ—¶é—´èŒƒå›´å·®å¼‚
    print(f"\nğŸ“… 2. æ—¶é—´èŒƒå›´å·®å¼‚:")
    print("-" * 60)
    
    for name, df in data.items():
        if 'timestamp' in df.columns and len(df) > 0:
            start_time = df['timestamp'].min()
            end_time = df['timestamp'].max()
            duration = (end_time - start_time).days
            
            print(f"{name:30}:")
            print(f"{'':30}  å¼€å§‹: {start_time}")  
            print(f"{'':30}  ç»“æŸ: {end_time}")
            print(f"{'':30}  è·¨åº¦: {duration} å¤©")
            print()
    
    # 3. æ•°æ®å€¼å·®å¼‚ï¼ˆä»¥virtual_priceä¸ºä¾‹ï¼‰
    print(f"\nğŸ’° 3. virtual_priceæ•°æ®å€¼å·®å¼‚:")
    print("-" * 60)
    
    for name, df in data.items():
        if 'virtual_price' in df.columns and len(df) > 0:
            vp_stats = df['virtual_price'].describe()
            print(f"{name:30}:")
            print(f"{'':30}  å‡å€¼: {vp_stats['mean']:.6f}")
            print(f"{'':30}  ä¸­ä½æ•°: {vp_stats['50%']:.6f}")
            print(f"{'':30}  æ ‡å‡†å·®: {vp_stats['std']:.6f}")
            print(f"{'':30}  æœ€å°å€¼: {vp_stats['min']:.6f}")
            print(f"{'':30}  æœ€å¤§å€¼: {vp_stats['max']:.6f}")
            print()
    
    # 4. æ•°æ®æ¥æºå·®å¼‚
    print(f"\nğŸ”„ 4. æ•°æ®æ¥æº(source)å·®å¼‚:")
    print("-" * 60)
    
    for name, df in data.items():
        if 'source' in df.columns:
            sources = df['source'].value_counts()
            print(f"{name:30}: {dict(sources)}")
        else:
            print(f"{name:30}: æ— sourceåˆ—")
    
    # 5. ç”Ÿæˆæ–¹å¼åˆ†æï¼ˆåŸºäºä»£ç é€»è¾‘ï¼‰
    print(f"\nğŸ—ï¸ 5. ç”Ÿæˆæ–¹å¼åˆ†æ:")
    print("-" * 60)
    print("batch_historical:")
    print("   - è°ƒç”¨ get_comprehensive_free_data() åæ·»åŠ å…ƒæ•°æ®")
    print("   - é¢å¤–æ·»åŠ : pool_type, priority åˆ—") 
    print("   - ç”¨äºæ‰¹é‡å¤„ç†å¤šä¸ªæ± å­")
    print()
    
    print("comprehensive_free_historical:")
    print("   - æ¥è‡ª get_comprehensive_free_data() æ–¹æ³•")
    print("   - ç»¼åˆå¤šä¸ªæ•°æ®æº: The Graph + DefiLlama + è‡ªå»ºæ•°æ®åº“")
    print("   - åŒ…å« source åˆ—æ ‡è¯†æ•°æ®æ¥æº")
    print()
    
    print("self_built_historical:")
    print("   - æ¥è‡ª build_historical_database() æ–¹æ³•")
    print("   - åŸºäºå®æ—¶æ•°æ® + éšæœºæ³¢åŠ¨ç”Ÿæˆåˆæˆå†å²æ•°æ®")
    print("   - ä¸åŒ…å« source åˆ—")
    print("   - æ—¶é—´åºåˆ—å¯èƒ½ä¸å…¶ä»–æ–‡ä»¶ä¸åŒ")
    print()
    
    # 6. æ•°æ®é‡å åº¦æ£€æŸ¥
    print(f"\nğŸ”— 6. æ•°æ®é‡å åº¦æ£€æŸ¥:")
    print("-" * 60)
    
    if len(data) >= 2:
        names = list(data.keys())
        for i in range(len(names)):
            for j in range(i+1, len(names)):
                name1, name2 = names[i], names[j]
                df1, df2 = data[name1], data[name2]
                
                if 'virtual_price' in df1.columns and 'virtual_price' in df2.columns:
                    # æ£€æŸ¥å‰10ä¸ªvirtual_priceå€¼çš„ç›¸å…³æ€§
                    common_length = min(10, len(df1), len(df2))
                    if common_length >= 5:
                        vp1 = df1['virtual_price'].head(common_length).values
                        vp2 = df2['virtual_price'].head(common_length).values  
                        
                        correlation = np.corrcoef(vp1, vp2)[0,1] if len(vp1) > 1 else 0
                        mae = np.mean(np.abs(vp1 - vp2))
                        
                        print(f"{name1} vs {name2}:")
                        print(f"   ç›¸å…³æ€§: {correlation:.4f}")
                        print(f"   å¹³å‡ç»å¯¹è¯¯å·®: {mae:.6f}")
                        print()
    
    # 7. ä½¿ç”¨å»ºè®®
    print(f"\nğŸ’¡ 7. ä½¿ç”¨å»ºè®®:")
    print("-" * 60)
    print("ğŸ¯ ç”¨é€”é€‰æ‹©:")
    print("   batch_historical:")
    print("     - é€‚ç”¨äºå¤šæ± å­æ‰¹é‡åˆ†æ")
    print("     - åŒ…å«æ± å­å…ƒæ•°æ®(type, priority)")
    print("     - æ¨èç”¨äºæ¨¡å‹è®­ç»ƒå¯¹æ¯”")
    print()
    
    print("   comprehensive_free_historical:")
    print("     - é€‚ç”¨äºå•æ± å­æ·±åº¦åˆ†æ") 
    print("     - æ•°æ®æ¥æºå¯è¿½æº¯")
    print("     - æ¨èç”¨äºæ•°æ®æºç ”ç©¶")
    print()
    
    print("   self_built_historical:")
    print("     - é€‚ç”¨äºåˆæˆæ•°æ®å®éªŒ")
    print("     - æ•°æ®è¾ƒä¸ºå¹³æ»‘ï¼Œéšæœºæ³¢åŠ¨å¯æ§")
    print("     - æ¨èç”¨äºç®—æ³•æµ‹è¯•")
    print()
    
    print("ğŸ”„ æ•°æ®è´¨é‡æ’åº:")
    print("   1. comprehensive_free_historical (æœ€å®Œæ•´)")
    print("   2. batch_historical (å¸¦å…ƒæ•°æ®)")
    print("   3. self_built_historical (åˆæˆæ•°æ®)")
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ åˆ†ææ€»ç»“")
    print("=" * 80)
    
    print("âœ… ä¸»è¦å‘ç°:")
    print("   1. ä¸‰ä¸ªæ–‡ä»¶ç»“æ„ç›¸ä¼¼ä½†åˆ—æ•°ä¸åŒ")
    print("   2. batch_historical åŒ…å«æœ€å¤šçš„å…ƒæ•°æ®åˆ—")
    print("   3. self_built_historical æ•°æ®å€¼æœ‰æ˜æ˜¾å·®å¼‚ï¼ˆåˆæˆæ•°æ®ï¼‰")
    print("   4. comprehensive å’Œ batch çš„æ•°æ®å€¼å‡ ä¹å®Œå…¨ç›¸åŒ")
    print("   5. æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰ç›¸åŒçš„è®°å½•æ•°(1460è¡Œ)")
    
    print(f"\nğŸ¯ æ¨èä½¿ç”¨:")
    print("   æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ: batch_historical")
    print("   æ•°æ®åˆ†æç ”ç©¶: comprehensive_free_historical") 
    print("   ç®—æ³•æµ‹è¯•: self_built_historical")

def compare_specific_columns():
    """æ¯”è¾ƒç‰¹å®šåˆ—çš„è¯¦ç»†å·®å¼‚"""
    
    print(f"\n" + "=" * 80)
    print("ğŸ”¬ ç‰¹å®šåˆ—è¯¦ç»†æ¯”è¾ƒ")
    print("=" * 80)
    
    cache_dir = Path("free_historical_cache")
    
    # è¯»å–æ–‡ä»¶
    batch_df = pd.read_csv(cache_dir / "3pool_batch_historical_365d.csv")
    comprehensive_df = pd.read_csv(cache_dir / "3pool_comprehensive_free_historical_365d.csv")
    
    # æ¯”è¾ƒç›¸åŒæ—¶é—´ç‚¹çš„æ•°æ®
    print("ğŸ“Š ç›¸åŒæ—¶é—´ç‚¹æ•°æ®æ¯”è¾ƒ (å‰5è¡Œ):")
    print("-" * 60)
    
    cols_to_compare = ['virtual_price', 'volume_24h', 'total_supply']
    
    for col in cols_to_compare:
        if col in batch_df.columns and col in comprehensive_df.columns:
            print(f"\n{col}:")
            print("batch_historical    comprehensive")
            for i in range(min(5, len(batch_df), len(comprehensive_df))):
                batch_val = batch_df[col].iloc[i]
                comp_val = comprehensive_df[col].iloc[i]
                match = "âœ“" if batch_val == comp_val else "âœ—"
                print(f"{batch_val:15.6f} {comp_val:15.6f} {match}")

if __name__ == "__main__":
    analyze_3pool_data_formats()
    compare_specific_columns() 